### SGD에서 batch size가 학습과 성능에 미치는 영향
- 배치 사이즈가 큰 경우 기울기를 계산하기 위해 더 많은 데이터를 사용하게 되므로 우리가 최적화 시켜야하는 전체 학습용 데이터를 사용한 해공간의 기울기 값과 유사한 기울기를 사용하므로 최적화가 더 수월해질 수 있다. 하지만 실제 최적화 시켜야할 문제공간이 평평한 경우에는 실제와 유사하게 근사된 기울기의 절대값이 작아 수렴 속도가 매우 느려질 수 있고, 극단적인 경우에는 극소점(local minima) 혹은 안장점(saddle point)에 빠져서 로스가 줄어들지 않을 수도 있다.
- 반면에 배치 사이즈가 작은 경우 상대적으로 부정확한 기울기를 사용한다는 단점이 있지만, 한번의 업데이트에 적은 계산 비용이 들어가 한번 업데이트 할 동안 여러번의 업데이트를 수행할 수 있고, 기울기의 부정확한 면이 랜덤성으로 작용해 실제 기울기가 낮은 구간이나 극소점, 안장점에서 쉽게 벗어날 가능성이 있다는 장점이 있다.
- Keskar et al(2017)에 따르면 배치 사이즈가 커질수록 일반화 성능이 떨어지는 현상이 관측되었다. 
- 실전에서는 배치 사이즈를 메모리에 올라갈 수 있는 한 최대로 설정하는 경우가 많다. 계산한 기울기를 이용해서 파라미터를 업데이트 과정에서는 동기화 작업이 필요하기 때문에 큰 배치 사이즈로 더 적게 업데이트를 한다고 하면, 작은 배치 사이즈로 업데이트를 많이 하는 것보다 병렬화하기 쉬워 계산 비용을 절약할 수 있기 때문이다.
- 하나의 연산장치를 사용하는 경우 연산의 효율성을 위해 배치 사이즈를 메모리에 올라갈 수 있는 한 최대한 크게 설정해도 일반화 성능이 떨어질 걱정을 하지 않아도 된다.


### Pytorch DataParallel
- nn.DataParallel로 model을 감싸면 학습을 할 때 다음과 같은 작업을 하는 것입니다. 위에서 언급한 대로 replicate → scatter → parallel_apply → gather 순서대로 진행합니다.
- DataParallel
![1_FpDHkWJhkLL7KxU01Lf9Lw](https://user-images.githubusercontent.com/65876994/109257492-a0233e80-783b-11eb-96db-7ef73ed3a6e0.png)
- DataParallelModel, DataParallelCriterion
![1_F6SXjBp6BCoFTZ26RKnz9A](https://user-images.githubusercontent.com/65876994/109256126-b2e84400-7838-11eb-8966-37e93528fe5d.png)
- [참조링크](https://medium.com/daangn/pytorch-multi-gpu-%ED%95%99%EC%8A%B5-%EC%A0%9C%EB%8C%80%EB%A1%9C-%ED%95%98%EA%B8%B0-27270617936b)
